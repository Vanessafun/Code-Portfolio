---
title: "BioA02"
author: "Wenyi Fang"
date: "3/24/2020"
output:
  pdf_document: default
  html_document: default
---

#Data and packages
```{r}
library(tidyverse)
library(tibble)
library(dplyr)
library(tidyr)
library(magrittr)
library(purrr)
library(ggplot2)
library(data.table)
library(caret)
library(ISLR)
library(pROC)
library(glmnet)
library(arm)
library(lmtest)
library(stringr)
library(MASS)

setwd("/Users/vanessafung/Desktop")
results.dt = read.table(file = "assignment2/lipids.txt",header = T, sep = "\t")
lipid.class = read.table(file = "assignment2/lipid-classes.txt",header = F, sep = "\t")

wdbc2 = read.csv(file = "assignment2/wdbc2.csv")

gdm.dt = read.table("assignment2/GDM.raw.txt",header = T)
gdm.annot = read.table("assignment2/GDM.annot.txt",header = T,na.strings = "NA", sep = "\t")
gdm.test = read.table("assignment2/GDM.test.txt",header = T)
gdm.study2 = fread("assignment2/GDM.study2.txt",header = T)

nki = read.csv(file = "assignment2/nki.csv")
```


#Problem 01 
##01-(a)
```{r}
#divide lipid specious into 4 column to extract classes names out
results.dt[, c("v1", "v2", "v3", "v4")] = str_split_fixed(results.dt$lipid.species, " ", 4)
#no class infomation is included in v2,v4 therefore delete them
results.dt = results.dt[, -c(5, 7)]

#fix class name in results.dt to be the same as class name in lipid-classes list
for (i in c(4, 5)) {
  results.dt[, i][which(results.dt[, i] == "CER")] = "Cer"
  results.dt[, i][which(results.dt[, i] == "Dag")] = "DAG"
  results.dt[, i][which(results.dt[, i] == "Tag")] = "TAG"
  results.dt[, i][which(results.dt[, i] == "tag")] = "TAG"
}

#use merge() to annotate specious name to the results.dt
for (i in c(1, 3)) {
  results.dt = merge(
    results.dt,
    lipid.class,
    by.x = paste("v", i, sep = ""),
    by.y = c("V1"),
    all.x = T
  )
}

#tidy the results.dt
results.dt = results.dt %>%
  mutate(class.name = if_else(is.na(results.dt$V2.x), results.dt$V2.y, results.dt$V2.x)) %$%
  .[, -c(1, 2, 6, 7)]

#Count the number of lipids that fall in each class
cou.w.class = results.dt %>%
  group_by(class.name) %>%
  count()
cou.w.class
```


##01-(b)
The normal approximation is acceptable in this instance.Portion1 is the portion of norm.pvalue reject the null when t.pvalue reject the null,which is 1,Portion2 is the portion of norm.pvalue is insignificant when t.pvalue is insignificant, which is also 1. This means t.pvalue and norm.pvalue result in the same conclusions in this dataset, therefore the normal approximation is acceptable in this instance.
```{r}
lipid.z.value = log(results.dt$oddsratio) / results.dt$se
results.dt = results.dt %>%
  mutate(
    t.p.value = 2 * pt(abs(lipid.z.value), 284, lower.tail = F),
    norm.p.value = 2 * pnorm(abs(lipid.z.value), lower.tail = F),
    zvalue = lipid.z.value
  )

#portion of pnorm and pt have the same significant conclution
portion1  = length(results.dt[which(results.dt$t.p.value <= 0.05 &
                                      results.dt$norm.p.value <= 0.05),]$lipid.species) / length(results.dt[which(results.dt$t.p.value <=                                                                                                                             0.05),]$lipid.species)
#portion of pnorm and pt have the same not significant conclution
portion2  = length(results.dt[which(results.dt$t.p.value > 0.05 &
                                      results.dt$norm.p.value > 0.05),]$lipid.species) / length(results.dt[which(results.dt$t.p.value >
                                                                                                                   0.05),]$lipid.species)
portion1#1
portion2#1

```


##01-(c)
```{r}
holm.bonferroni = function(results.dt, alpha){
  parg.results = arrange(results.dt,t.p.value)
  k = 0
  while (parg.results$t.p.value[k+1]< alpha/(length(parg.results$t.p.value)+1-k-1)){
    k = k+1 
  }
  print(k)
  return(parg.results[c(1:k),])
}
```


##01-(d)
```{r}
benjamini.hochberg  =  function(results.dt, q){
  parg.results = arrange(results.dt,t.p.value)
  k = 0
  while (parg.results$t.p.value[k+1]<=(k+1)*q/length(parg.results$t.p.value)){
    k = k+1
  }
  print(k)
  return(parg.results[c(1:k),])
}

```


##01-(e)
```{r}
sub.df1 = holm.bonferroni(results.dt,0.05)
sub.df2 = benjamini.hochberg(results.dt,0.01)

{plot(log(results.dt$oddsratio),-log10(results.dt$t.p.value),col = "black" ,main = "Volcano plot ",xlab = "coefficient",ylab = "-log10(t.pvalue)")
points(log(sub.df2$oddsratio),-log10(sub.df2$t.p.value),col = "red",pch = 23)
points(log(sub.df1$oddsratio),-log10(sub.df1$t.p.value), pch=22, cex=0.5,col = "blue")
legend('topleft',legend = c("HB","BH"),col = c("blue","red"),pch = c(22,23),cex=1)}
```


##01-(f)
```{r}
sub.df3 = benjamini.hochberg(results.dt,0.05)
sub.df1;sub.df3
```



#Problem 02
##02-(a)
```{r}
set.seed(1)
inTrain = createDataPartition(wdbc2$id, p = 0.7)#randomly split 70% data into training set
wdbc2Train = wdbc2[inTrain$Resample1,-1]#trim off the id column
wdbc2Test = wdbc2[-inTrain$Resample1,-1]

x_train = model.matrix(diagnosis ~ ., wdbc2Train)[,-1] # trim off the intercept column leaving only the predictors
y_train = as.numeric(wdbc2Train$diagnosis)

x_test = model.matrix(diagnosis ~ ., wdbc2Test)[,-1]
y_test = as.numeric(wdbc2Test$diagnosis)

grid = 10 ^ seq(10, -2, length = 100)#a sequence of lambda

cv.out.ridge = cv.glmnet(
  x_train,
  y_train,
  alpha = 0,
  lambda = grid,
  family  = "binomial",
  type.measure = "auc"
) # Fit ridge regression model on training data

cv.out.lasso = cv.glmnet(
  x_train,
  y_train,
  alpha = 1,
  lambda = grid,
  family  = "binomial",
  type.measure = "auc"
) # Fit lasso regression model on training data

cv.out.ridge$lambda.min;cv.out.lasso$lambda.min
```


##02-(b)
```{r}
cv.auc.ridge = cv.out.ridge$cvm
auc.opt.ridge = cv.auc.ridge[which(cv.out.ridge$lambda == cv.out.ridge$lambda.min)]
auc.1se.ridge = cv.auc.ridge[which(cv.out.ridge$lambda == cv.out.ridge$lambda.1se)]

cv.auc.lasso = cv.out.lasso$cvm
auc.opt.lasso = cv.auc.lasso[which(cv.out.lasso$lambda == cv.out.lasso$lambda.min)]
auc.1se.lasso = cv.auc.lasso[which(cv.out.lasso$lambda == cv.out.lasso$lambda.1se)]

auc.df = data.frame(
  ridge.auc = c(auc.opt.ridge, auc.1se.ridge),
  lasso.auc = c(auc.opt.lasso, auc.1se.lasso),
  row.names = c("optimal.lambda", "1se.lambda")
)
auc.df
```


##02-(c)
Comments on results:model size  of ridge is 30 but lasso is 8.This means lasso penalty more than ridge in this problem.Because ridge regression can't zero out coefficients; thus, it either end up including all the coefficients in the model, or none of them.In this problems, ridge model including all coefficeints. In contrast, the lasso does both parameter shrinkage and variable selection automatically.
```{r}
sum.dt = data.frame(
  ridge.modelsize = c(cv.out.ridge$nzero[which(cv.out.lasso$lambda == cv.out.lasso$lambda.min)],
                      cv.out.ridge$nzero[which(cv.out.lasso$lambda == cv.out.lasso$lambda.1se)]),
  lasso.modelsize = c(cv.out.lasso$nzero[which(cv.out.lasso$lambda == cv.out.lasso$lambda.min)],
                      cv.out.lasso$nzero[which(cv.out.lasso$lambda == cv.out.lasso$lambda.1se)]),
  ridge.auc = c(auc.opt.ridge, auc.1se.ridge),
  lasso.auc =  c(auc.opt.lasso, auc.1se.lasso),
  row.names = c("optimal.lambda", "1se.lambda")
)
signif(sum.dt, 3)

```



##02-(d)
```{r}
basemodel = glm(diagnosis ~ .,
                data = na.omit(wdbc2Train),
                family = binomial(link = 'logit'))
modelB = stepAIC(basemodel,
                 direction = "back",
                 scale = T,
                 trace = F)

coef.modelb = as.data.frame(coef(summary(modelB)))
signif.coef.modelb = coef.modelb[which(coef.modelb$`Pr(>|z|)` <= 0.05), ]#extract significant coefficients
signif.coef.modelb = signif.coef.modelb[sort(abs(signif.coef.modelb$Estimate),
                                             index.return = TRUE,
                                             decreasing = TRUE)$ix, ]
signif.coef.modelb
```



##02-(e)
These variables entered the model and was later on discarded: perimeter.worst, texture, area.stderr and area.
```{r}
basenull = glm(diagnosis ~ 1, data = wdbc2Train, family = binomial)
modelS =  stepAIC(basenull,
                  scope = list(upper = basemodel),
                  direction = "both",
                  scale = T,
                  trace = F)
summary(modelS)

coef.models = as.data.frame(coef(summary(modelS)))
signif.coef.models = coef.models[which(coef.models$`Pr(>|z|)`<=0.05),]
signif.coef.models = signif.coef.models[sort(abs(signif.coef.models$Estimate),index.return=TRUE,decreasing=TRUE)$ix,]
signif.coef.models
```


##02-(f)
Employ AIC standard to choose model, model S performs better with a smaller AICï¼ŒAIC of model B is 103.6, AIC of model S is 97.9
```{r}
modelB$aic;modelS$aic
```


##02-(g)
Training auc of model B is 0.995,Training auc of model S is 0.994
```{r}
modelB.pred = predict(modelB, newdata = as.data.frame(x_train))
modelS.pred = predict(modelS, newdata = as.data.frame(x_train))

roc_B <- roc(y_train, modelB.pred)
train.aucB = auc(roc_B)
roc_S <- roc(y_train, modelS.pred)
train.aucS = auc(roc_S)
train.aucB;train.aucS
```


##02-(h)
All auc is over 0.9, this may indicates that they're all slightly overfiting. According to test auc,Ridge regression model has the best test performance, Lasso also performs well.Comparing trainig auc and test auc of Ridge and Lasso, there's no significant difference between them. 
ModelS performs the best in traning auc, however, ModelS's test auc is lower than Ridge and Lasso, which implies overfitting in training. 
According to ROC plot , test fitting performances: Ridge is better than Lasso,Lasso is better than Backward>Stepwise
```{r}
pred.ridge = predict(cv.out.ridge,
                     newx = x_test,
                     type = "response",
                     s = cv.out.ridge$lambda.1se)
pred.lasso = predict(cv.out.lasso,
                     newx = x_test,
                     type = "response",
                     s = cv.out.lasso$lambda.1se)
pred.modelb = predict(modelB, newdata = as.data.frame(x_test))
pred.models = predict(modelS, newdata = as.data.frame(x_test))

roc_rid <- roc(y_test, pred.ridge)
roc_lasso <- roc(y_test, pred.lasso)
roc_B <- roc(y_test, pred.modelb)
roc_S <- roc(y_test, pred.models)
test.aucR = auc(roc_rid)
test.aucL = auc(roc_lasso)
test.aucB = auc(roc_B)
test.aucS = auc(roc_S)

test.train.auc = data.frame(
  test.auc = c(test.aucR,test.aucL,test.aucB,test.aucS),
  train.auc = c(auc.opt.ridge,auc.opt.lasso,train.aucB,train.aucS),
  row.names = c("Ridge","Lasso","Backward","Stepwise"))
test.train.auc

{plot(roc_rid,main = "ROC Plot")
lines(roc_lasso,col = "red")
lines(roc_B,col = "blue")
lines(roc_S,col = "green")
legend('bottomright',legend = c("Ridge","Lasso","Backward","Stepwise"),col = c("black","red","blue","green"),pch = 20,cex=1)}

```



#Problem 03
##03-(a)
```{r}
snp.allele.dt = gdm.dt[, -c(1:3)]

#mean imputation
for (i in 4:179) {
  gdm.dt[, i][is.na(gdm.dt[, i])] <-
    mean(gdm.dt[, i], na.rm = TRUE)
}

```


##03-(b)
```{r}
univ.glm.test <- function(x, y, order = FALSE) {
  SNP.names = as.character()
  reg.coeff = as.numeric()
  odds = as.numeric()
  se = as.numeric()
  pvalue = as.numeric()
  
  for (j in 1:ncol(x)) {
    model = glm(y ~ x[, j], family = binomial(link = "logit"))
    SNP.names[j] = colnames(x)[j]
    reg.coeff[j] = model$coefficients[2]
    odds[j] = exp(model$coefficients[2])
    se[j] = coef(summary(model))[2, 2]
    pvalue[j] = coef(summary(model))[2, 4]
  }
  snp.logis.sum.dt = data.table(SNP.names, reg.coeff, odds, se, pvalue)
  
  if (order == T) {
    snp.logis.sum.dt = arrange(snp.logis.sum.dt, pvalue)
  }
  
  return(snp.logis.sum.dt)
}

```


##03-(c)
select significant SNPs out, then extract the maximum and minimum coefficients from those significant snps to obtain summarized statistics and confidence interval.
```{r}
gwas = univ.glm.test(x = gdm.dt[,-c(1:3)], y = gdm.dt$pheno, order = T)

signif.snp = gwas[which(gwas$pvalue <= 0.05), ]#extract significant SNPs out
max.risk = signif.snp[which(signif.snp$reg.coeff == max(signif.snp$reg.coeff)), ]
min.risk = signif.snp[which(signif.snp$reg.coeff == min(signif.snp$reg.coeff)), ]

max.int.95 = max.risk$reg.coeff+1.96 * c( - max.risk$se, max.risk$se)
min.int.99 = max.risk$reg.coeff+2.58 * c( - min.risk$se, min.risk$se)
min.int.95 = min.risk$reg.coeff+1.96 * c( - min.risk$se, min.risk$se)
max.int.99 = max.risk$reg.coeff+2.58 * c( - max.risk$se, max.risk$se)

summary.gwas = summary(gwas)
sum.ci.gwas = data.frame(
  row.names  = c(max.risk$SNP.names,"", min.risk$SNP.names,"."),
  odds.interval.95 = exp(c(max.int.95, min.int.95)),
  odds.interval.99 = exp(c(max.int.99, min.int.99)))
summary.gwas;sum.ci.gwas
```


##03-(d)
```{r}
gwas[, c("snp", "allele")] = str_split_fixed(gwas$SNP.names, "_", 2)
gwas.annot = merge(gwas, gdm.annot,all.x = T)#merge gwas with gdm.annot by snp names

hit.snp = gwas.annot[which(gwas.annot$pvalue < 10 ^ -4), ][, c(2, 7, 8, 10)]

#genes with 1Mb window
gene.1Mb.range1 = c(gwas.annot[28,]$pos-1e06,gwas.annot[28,]$pos+1e06)#28 is the row number of the first hit snp
gene.1Mb.range2 = c(gwas.annot[76,]$pos-1e06,gwas.annot[76,]$pos+1e06)#76 is the row number of the second hit snp
gene.1Mb.hit1 = gwas.annot[which(gwas.annot$pos >=gene.1Mb.range1[1]&gwas.annot$pos <=gene.1Mb.range1[2]),]
gene.1Mb.hit2 = gwas.annot[which(gwas.annot$pos >=gene.1Mb.range2[1]&gwas.annot$pos <=gene.1Mb.range2[2]),]
as.data.frame(gene.1Mb.hit1$gene);as.data.frame(gene.1Mb.hit2$gene)
```


##03-(e)
```{r}
gdm.dt = as.data.table(gdm.dt)
gwas = as.data.table(gwas)
gwas.annot = as.data.table(gwas.annot)

snp.p4 = gwas[which(gwas$pvalue <= 1e-4), ]
snp.p3 = gwas[which(gwas$pvalue <= 1e-3), ]
snp.fto = gwas.annot[which(gwas.annot$gene == "FTO"),]

gdm.p4 <- gdm.dt[, .SD, .SDcols = gwas[pvalue < 1e-4]$SNP.names]
gdm.p3 <- gdm.dt[, .SD, .SDcols = gwas[pvalue < 1e-3]$SNP.names]
gdm.fto <- gdm.dt[, .SD, .SDcols = gwas.annot[gene == "FTO"]$SNP.names]

score.p4 = as.matrix(gdm.p4) %*% snp.p4$reg.coeff
score.p3 = as.matrix(gdm.p3) %*% snp.p3$reg.coeff
score.fto = as.matrix(gdm.fto) %*% snp.fto$reg.coeff

gdm.dt[, "score1"] = score.p4
gdm.dt[, "score2"] = score.p3
gdm.dt[, "score3"] = score.fto

modelp4.score1 = glm(
  pheno~score1,
  data = gdm.dt,
  family = binomial,
  na.action = na.exclude
)
modelp3.score2 = glm(
  pheno~score2,
  data = gdm.dt,
  family = binomial,
  na.action = na.exclude
)
modelfto.score3 = glm(
  pheno~score3,
  data = gdm.dt,
  family = binomial,
  na.action = na.exclude
)

sum.mp4 = coef(summary(modelp4.score1))
sum.mp3 = round(coef(summary(modelp3.score2)),2)
sum.mfto = round(coef(summary(modelfto.score3)),2)

score.fit.sum = data.frame(
  oddratio = round(exp(c(sum.mp4[2, 1], sum.mp3[2, 1], sum.mfto[2, 1])),2),
  CI.95 = c(
    paste("(", round(sum.mp4[2, 1] - 1.96 * sum.mp4[2, 2],2), round(sum.mp4[2, 1] + 1.96 *
            sum.mp4[2, 2],2), ")"),
    paste("(", round(sum.mp3[2, 1] - 1.96 * sum.mp3[2, 2],2), round(sum.mp3[2, 1] + 1.96 *
            sum.mp3[2, 2],2), ")"),
    paste("(", round(sum.mfto[2, 1] - 1.96 * sum.mfto[2, 2],2), round(sum.mfto[2, 1] + 1.96 *
            sum.mfto[2, 2],2), ")")
  ),
  pvalue = c(sum.mp4[2, 4], sum.mp3[2, 4], sum.mfto[2, 4]),
  row.names = c("p<e-04","p<e-03","FTO")
)
score.fit.sum                                                        
```


##03-(f)
```{r}
gwas.test = univ.glm.test(x=gdm.test[,-c(1:3)],y = gdm.test$pheno,order = T)
gwas.annot.test = merge(gwas.test, gdm.annot,by.x = "SNP.names",by.y = "snp")#merge gwas with gdm.annot by snp names

gwas.test = as.data.table(gwas.test)
gdm.test = as.data.table(gdm.test)
gwas.annot.test = as.data.table(gwas.annot.test)

gdm.p4.test <- gdm.test[, .SD, .SDcols = gwas[pvalue < 1e-4]$snp]
gdm.p3.test <- gdm.test[, .SD, .SDcols = gwas[pvalue < 1e-3]$snp]
gdm.fto.test <- gdm.test[, .SD, .SDcols = gwas.annot[gene == "FTO"]$snp]

score.p4.test = as.matrix(gdm.p4.test) %*% snp.p4$reg.coeff
score.p3.test = as.matrix(gdm.p3.test) %*% snp.p3$reg.coeff
score.fto.test = as.matrix(gdm.fto.test) %*% snp.fto$reg.coeff

gdm.test[, "score1"] = score.p4.test
gdm.test[, "score2"] = score.p3.test
gdm.test[, "score3"] = score.fto.test

```


##03-(g)
The test log-likelihood for the predicted probabilities from the three genetic risk score models.
```{r}
#predicted outcomes from models fitted at point (e)  
pred.p4 = predict(modelp4.score1, newdata = gdm.test)
pred.p3 = predict(modelp3.score2, newdata = gdm.test)
pred.fto = predict(modelfto.score3, newdata = gdm.test)

#define a function to calculate test log likelihood
test.loglik <- function(s_model,pred,score) {
    log_lik <- sum(pred*s_model$coefficients[2]%*%score-log(1+exp(s_model$coefficients[2]*score)))
    return(log_lik)
}

# Compute the test log-likelihood for the predicted probabilities from the three genetic risk score models
log.likeli.p4 = test.loglik(modelp4.score1,pred.p4,gdm.test$score1)
log.likeli.p3 = test.loglik(modelp3.score2,pred.p3,gdm.test$score2)
log.likeli.fto = test.loglik(modelfto.score3,pred.fto,gdm.test$score3)

loglik = data.frame(
  loglikeli = c(log.likeli.p4,log.likeli.p3,log.likeli.fto),
  row.names = c("p<e04","p<e03","FTO")
)
loglik
```


##03-(h)meta-analysis
Because gwas in (c) has only one ellele,therefore only check whether snp and effect allele is corresponded or not in these two gwas results.
```{r}
#Combine snp and effect allele in gdm.study2 into a new column "Snp.names"
gdm.study2[,"Snp.names"]<-paste(gdm.study2$snp,gdm.study2$effect.allele,sep = "_")


#check snp and effect allele is corresponded or not
gwas1= gwas[SNP.names %in% gdm.study2$Snp.names] 
gwas2 = gdm.study2[Snp.names %in% gwas$SNP.names]

beta1 <- gwas1$reg.coeff
beta2 <- gwas2$beta


weight.gwas1 <- 1 / gwas1$se^2
weight.gwas2 <- 1 / gwas2$se^2

beta.ma <- (weight.gwas1 * beta1 + weight.gwas2 * beta2) / (weight.gwas1 + weight.gwas2)
se.ma <- sqrt(1 / (weight.gwas1 + weight.gwas2))

pval.ma <- 2 * pnorm(abs(beta.ma / se.ma), lower.tail=FALSE)
plot(-log10(gwas1$pvalue), -log10(pval.ma), xlim=c(0, 8), ylim=c(0, 16), xlab="p-values from gwas1", ylab="p-values from meta-analysis")
```


#Problem 04
##04-(a)
```{r}
cor.matrix = cor(nki[, -(1:6)])

flattenCorrMatrix <- function(cormat) {
  ut = upper.tri(cormat)
  data.frame(
    variable1 = rownames(cormat)[row(cormat)[ut]],
    variable2 = rownames(cormat)[col(cormat)[ut]],
    cor = (cormat)[ut]
  )
}

nki.pair.df = flattenCorrMatrix(cor.matrix)
nki.pair.df[which(abs(nki.pair.df$cor) > 0.8), ]
```


##04-(b)
The percentage of variance explained by the first two components is 33.16%.
Rule of identify 4 genes: According to scatter plot of PC1 vs PC2, I found there're 4 "outliers" around the bottom,therefore I ordered PC2 in increasing order, and exrtact the first 4 gene as the most different group,they are ZNF533,MMP9,CDCA7,SCUBE2.
```{r}
nki.pca = prcomp(t(nki[, -(1:6)]),
                  center = TRUE,
                  scale  = TRUE)
summary(nki.pca)

#scatter plot of PC1 and PC2
plot(nki.pca$x[, 1:2], main = "Projection of variables on the first 2 PCs")

#identify 4 genes
PC2 = nki.pca$x[,2]
sort(PC2)[1:4]
```


##04-(c)
I use correaltion to test  3 principle components and outcomes are associated or not. PC1 and PC2 are almost equally associate with unadjusted and adjusted model according to correlation. PC3 is more associated with unadjusted model (cor = 0.173), correlation between adjusted model outcomes and PC is 0.079.
```{r}
patient.nki.pca = prcomp(nki[, -(1:6)], scale. = T)

unadj.moel = glm(Event ~ ., data = nki[, -(2:6)], family = "binomial")
adj.modle = glm(Event ~ ., data = nki, family = "binomial")

out.unadj = predict(unadj.moel)
out.adj = predict(adj.modle)

#Use cor to test whether principle components 1 to 3 is associated with models ourtcomes
cor.pc.adjout = NULL
cor.pc.unadjout = NULL
for (i in 1:3) {
  cor.pc.adjout[i] = cor(patient.nki.pca$x[, i], out.adj)
  cor.pc.unadjout[i] = cor(patient.nki.pca$x[, i], out.unadj)
}

cor.pc.outcome = data.frame(cor.pc.unadjout,
                            cor.pc.adjout,
                            row.names = c("PC1", "PC2", "PC3"))
cor.pc.outcome
```


##04-(d)
AUC of Model penalized all variables is 0.80 and auc of Model only penalize gene is 0.75,which is out of my expectation,beacuse modle with less covariates being penalized should have a larger auc.In this problem, model penalized all variables is probably overfitted. Besides, model penalized all variables has a smaller model size(35 for optimal lambda and 4 for 1se lambda) than model only penalize gene(55 for optimal lambda and 7 for 1se lambda).Generally, lasso might perform better in a situation where some of the predictors have large coefficients, in this problem, perhaps gene predicators in the second model have very small coefficients.
```{r}
set.seed(1)
x_nki = prepareX(nki[,-1])#transform original design matrix to fit the glmnet object

model.all.lasso = cv.glmnet(
  x_nki,
  nki$Event,
  family = "binomial",
  alpha = 1,
  type.measure = "auc"
)

model.penal.lasso = cv.glmnet(
  x_nki,
  nki$Event,
  family = "binomial",
  alpha = 1,
  penalty.factor = c(rep(0, 7), rep(1, 70)),
  type.measure = "auc"
)#penalty factor = 0 repeat 7 times because 5 non-gene variables are transformed into 7 dummies in x_nki

model.all.lasso;model.penal.lasso

#calculate AUC 
all.pred = predict(model.all.lasso,x_nki)
penal.pred = predict(model.penal.lasso,x_nki)
all.roc = roc(nki$Event,all.pred)
penal.roc = roc(nki$Event,penal.pred)
all.auc = all.roc$auc
penal.auc = penal.roc$auc
all.auc;penal.auc

```
